{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Polyvyannaya/Polyvyannaya/blob/main/NN_HW6_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at3nuxAQIOjM"
      },
      "source": [
        "# Введение в искусственные нейронные сети\n",
        "# Урок 6. Сегментация"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Домашнее задание\n",
        "\n",
        "Попробуйте обучить нейронную сеть U-Net на любом другом датасете. Опишите в комментарии к уроку - какой результата вы добились от нейросети? \n",
        "Что помогло вам улучшить ее точность?"
      ],
      "metadata": {
        "id": "dW5sq56FsyDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kC1CRv8sobe"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih3XANATsobf"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSi1GEtHsobf"
      },
      "outputs": [],
      "source": [
        "pip install git+https://github.com/tensorflow/examples.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfteXldvsobg"
      },
      "outputs": [],
      "source": [
        "pip install -U tfds-nightly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow -latest"
      ],
      "metadata": {
        "id": "GSgq3_WQuE--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "00njoOzyuKUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz-zopyJsobg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.experimental.set_visible_devices([], 'GPU')\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation, MaxPooling2D, Conv2D, BatchNormalization\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras.callbacks import EarlyStopping \n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb_nModdsobh"
      },
      "outputs": [],
      "source": [
        "# метрика на Tensorflow\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sops_nLsobh"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  %tensorflow_version only exists in Colab.\n",
        "  #%tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2EFbcvHsobh"
      },
      "source": [
        "Загрузка датасета caltech_birds2010\n",
        "\n",
        "> Блок с отступами\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-B1YaZ3sobi"
      },
      "outputs": [],
      "source": [
        "ds_names = ( 'caltech_birds2010:0.*.*',)\n",
        "dataset_all, info = tfds.load(ds_names[0], split = ['train[:10%]','test[-10%:]'], with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JT4g1Iepsobj"
      },
      "outputs": [],
      "source": [
        "info"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Следующий код выполнит простую аугументацию данных посредством переворота изображений. В дополнение изображение будет нормализовано к 0 и 1. Пиксели сегментационной маски будут помечены {1, 2, 3}, но для удобства из данного цифрового ряда будет вычтено по 1 и в итоге получиться {0, 1, 2}"
      ],
      "metadata": {
        "id": "GMZF9GHovzLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "#   input_mask -= 1\n",
        "  return input_image, input_mask"
      ],
      "metadata": {
        "id": "5G6mMqjbvpHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def load_image_train(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "metadata": {
        "id": "hVyYGtpCv3h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def load_image_test(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "metadata": {
        "id": "rFNTnx2axw1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Датасет уже содержит необходимые тестовый и тренировочный сплиты, поэтому давайте использовать их."
      ],
      "metadata": {
        "id": "4bjjGkm8x-0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 128\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // 10 // BATCH_SIZE"
      ],
      "metadata": {
        "id": "4_bVexJDx99b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# генераторы\n",
        "train = dataset_all[0].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test = dataset_all[1].map(load_image_test)"
      ],
      "metadata": {
        "id": "s5zRQOBSyM9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "aoJo-Nu_yQnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте посмотрим на пример изображения из датасета и соотвествующую ему маску из датасета"
      ],
      "metadata": {
        "id": "tD6wCoHmyYps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2abpKkcEyUiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, mask in test_dataset.take(1):\n",
        "  sample_image, sample_mask = image, mask\n",
        "display([sample_image[0,:,:,:], sample_mask[0,:,:,:]])"
      ],
      "metadata": {
        "id": "gPSCkq7e9_OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_mask.numpy().min(),sample_mask.numpy().max()"
      ],
      "metadata": {
        "id": "ppXCLl_G-Vzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_mask.dtype"
      ],
      "metadata": {
        "id": "pLUj8o_PSHdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определение модели\n",
        "Будем использовать модифицированный U-Net. В качестве энкодера будет использоваться предтренированный MobileNetV2. Декодером будет апсемпл блок уже имплементированный в TensorFlow examples Pix2pix tutorial. Причина по который будет испольваться три канала заключается в том что у нас 3 возможных лейбла на каждый пиксель. Можно это воспринимать как классиификацию где кажедый пиксель будет принадлежать одному из трех классов."
      ],
      "metadata": {
        "id": "msLKosymSRfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_CHANNELS = 3"
      ],
      "metadata": {
        "id": "DRDYDps_SWh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как упоминалось ранее энкодером будет предтренированный MobileNetV2, который подготовлен и готов к использованию - tf.keras.applications. Энкодер состоит из определенных аутпутов из средних слоев модели. Обратите внимание энкодр не будет участвовать в процессе тренировкие модели."
      ],
      "metadata": {
        "id": "J7VWphjPSgsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)"
      ],
      "metadata": {
        "id": "T_uEJ7yVSaii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the activations of these layers\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',   # 64x64\n",
        "    'block_3_expand_relu',   # 32x32\n",
        "    'block_6_expand_relu',   # 16x16\n",
        "    'block_13_expand_relu',  # 8x8\n",
        "    'block_16_project',      # 4x4\n",
        "]\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False"
      ],
      "metadata": {
        "id": "DV6HS7v1Sa93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Декодер/апсемплер это просто серия апсемпл блоков имплементированнхы в TensorFlow examples."
      ],
      "metadata": {
        "id": "gf_Uua2CS0Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "]"
      ],
      "metadata": {
        "id": "QBZ5fFbzSbQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model(output_channels):\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  # This is the last layer of the model\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      output_channels, 3, strides=2,\n",
        "      padding='same')  #64x64 -> 128x128\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "metadata": {
        "id": "0rDxg1qBS6S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тренировка модели\n",
        "\n",
        "Теперь, все что осталось это скомпилировать модель и начать процесс ее тренировки. Loss-функция, которую будем использовать - losses.SparseCategoricalCrossentropy(from_logits=True). Причина использования данной loss-функции заключается в том, что нейросеть пытается назначить каждому пикселю лейбл, также как в задачах предсказания класса. Для модели в которой 3 каннала каждый из которых пытается предсказать класс losses.SparseCategoricalCrossentropy(from_logits=True) обычно также рекомендуется. На выходе нейросети каждому пикселю назначается лейбл с наибольшим значением. Это то, что делает функция create_mask."
      ],
      "metadata": {
        "id": "X44xy3z4TE5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet_model(OUTPUT_CHANNELS)\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rR5Py2trS6wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на получившуюся архитектуру модели."
      ],
      "metadata": {
        "id": "vS966Y03TRHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydot"
      ],
      "metadata": {
        "id": "yeD3lMb8S7Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install graphviz"
      ],
      "metadata": {
        "id": "rGw3YpLbTak_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "HuQwEg9iTmGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте попробуем сделать предсказание с помощью нашей модели до того как началось обучение."
      ],
      "metadata": {
        "id": "zBYYKIyqTt0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]"
      ],
      "metadata": {
        "id": "HugAtNk4TxHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      print(1)\n",
        "      pred_mask = model.predict(image)\n",
        "      display([image[0], mask[0], create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([sample_image[0,:,:,:], sample_mask[0,:,:,:],\n",
        "             create_mask(model.predict(sample_image[:,:,:]))])\n",
        "show_predictions()"
      ],
      "metadata": {
        "id": "vk6LOaVWT2Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте осуществлять мониторинг того как улучшается работа модели в процессе обучения. Для завершения этой задачи callback функция определена ниже."
      ],
      "metadata": {
        "id": "dUboUlf6T_R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
      ],
      "metadata": {
        "id": "r81AyTziUDaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EPOCHS = 5 # увеличьте при необходимости\n",
        "EPOCHS = 15\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_STEPS = info.splits['test'].num_examples//10//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=test_dataset,\n",
        "                          callbacks=[DisplayCallback()])"
      ],
      "metadata": {
        "id": "MRsuKjVZUK4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "\n",
        "epochs = range(EPOCHS)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 5])\n",
        "plt.grid('on')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bwh00M_MUutp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions\n",
        "Сделаем несколько предсказаний. Используем количество эпох 15, с увеличением для модель дает более точные результаты."
      ],
      "metadata": {
        "id": "RayZLIiAU4xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_predictions(test_dataset, 5)"
      ],
      "metadata": {
        "id": "2IxqRcy2U2gF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}